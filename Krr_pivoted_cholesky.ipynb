{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1891dd-657b-4aca-82ca-442fe977f913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from timeit import default_timer as timer \n",
    "from sys import getsizeof\n",
    "from matplotlib import pyplot as plt\n",
    "import cupyx\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17889b62-baf9-4984-9894-3a6156995277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def pivoted_cholesky_cpu(matrix, max_rank, max_error_tolerance=0.001):\n",
    "\n",
    "\n",
    "#Pivoted_cholesky_cpu : to compute PCD in CPU \n",
    "#parameters taken: positive semi definite matrix, maximum rank of the approximation required, maximum error tolerance\n",
    "#returns list : [approximated matrix LL^T, rank_list [1...max_rank], norm list containing norm LL^T for all ranks, time taken for each rank in CPU] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6078c61-3356-498e-955c-87004d763115",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#[1]: H Harbrecht, M Peters, R Schneider. On the low-rank approximation by the pivoted Cholesky decomposition. Applied numerical mathematics, 62(4):428-440, 2012.\n",
    "#reference : https://github.com/tensorflow/probability/blob/v0.12.2/tensorflow_probability/python/math/linalg.py#L264-L404\n",
    "\n",
    "def pivoted_cholesky_cpu(matrix, max_rank, max_error_tolerance=1e-3):\n",
    "    \n",
    "    #initialize result lists\n",
    "    norm_array = [] \n",
    "    rank_array = []\n",
    "    time_array = []\n",
    "    \n",
    "    if max_rank > np.linalg.matrix_rank(matrix): # input max rank should not exceed full rank of original matrix\n",
    "        max_rank = np.linalg.matrix_rank(matrix)\n",
    "    \n",
    "    matrix_shape = np.asarray(matrix.shape)\n",
    "    matrix_diag = np.diagonal(matrix)\n",
    "    orig_error = np.amax(matrix_diag)\n",
    "    \n",
    "    Error_array = []\n",
    "    norm_array = []\n",
    "    \n",
    "    start = timer()\n",
    "    \n",
    "    def body(m, pchol, perm, matrix_diag):\n",
    "        \n",
    "        maxi = np.argmax(matrix_diag[perm[m:]]) + m  # taking index of highest diagonal element\n",
    "\n",
    "        maxval = matrix_diag[perm][maxi] # value of highest diagonal element\n",
    "        perm[m], perm[maxi] = perm[maxi], perm[m]  \n",
    "\n",
    "        row = matrix[perm[m]][perm[m + 1:]] \n",
    "\n",
    "        \n",
    "        def batch_gather(params, indices, axis=-1):\n",
    "            return np.take(params, indices, axis=axis)\n",
    "        \n",
    "        prev_rows = pchol[..., :m, :]\n",
    "        prev_rows_perm_m_onward = batch_gather(prev_rows, perm[..., m + 1:])\n",
    "        prev_rows_pivot_col = batch_gather(prev_rows, perm[..., m:m + 1])\n",
    "        \n",
    "        row -= np.sum(prev_rows_perm_m_onward * prev_rows_pivot_col, axis = -2)\n",
    "\n",
    "        pivot = np.sqrt(maxval) # worst approximated element used as a pivot\n",
    "        \n",
    "        row /= pivot # row elements divided by pivot\n",
    "\n",
    "        row = np.concatenate([[pivot], row], -1)\n",
    "        \n",
    "        matrix_diag_copy = matrix_diag.copy()\n",
    "        matrix_diag_copy[perm[m:]] -= row**2\n",
    "        \n",
    "        pchol[m, perm[m:]] = row # adding row to pchol\n",
    "        pchol_shape = pchol.shape\n",
    "\n",
    "        return m + 1, pchol, perm, matrix_diag_copy\n",
    "\n",
    "    m = np.int64(0)\n",
    "    pchol = np.zeros(matrix_shape, dtype=matrix.dtype)[..., :max_rank, :]\n",
    "    perm = np.broadcast_to(\n",
    "        range(matrix_shape[-1]), matrix_shape[:-1])\n",
    "    perm = perm.copy()\n",
    "\n",
    "    def check_cond(m, pchol, perm, matrix_diag):\n",
    "        del pchol\n",
    "        del perm\n",
    "        error = np.linalg.norm(matrix_diag, ord=1, axis=-1)\n",
    "        max_error = np.amax(error / orig_error)\n",
    "        return (m >= max_rank) |( max_error <= max_error_tolerance) # loop ends if m exceeds max rank or error is less than max allowed error tolerance\n",
    "\n",
    "    while(1): #Each iteration rank is increased (one more row is added so that it makes a better approximation)\n",
    "        m, pchol, perm, matrix_diag = body(m, pchol, perm, matrix_diag)\n",
    "        pchol_T = np.transpose(pchol)\n",
    "        lr_approx = np.matmul(pchol_T, pchol)\n",
    "        time_array.append(timer() - start) \n",
    "        rank_array.append(np.linalg.matrix_rank(lr_approx))\n",
    "        norm_array.append(np.linalg.norm(lr_approx))\n",
    "        if (m % 50 == 0):\n",
    "            print(\" computing... rank {} approximation completed (CPU) \\n\".format(m))\n",
    "        if check_cond(m, pchol, perm, matrix_diag):\n",
    "            break\n",
    "    \n",
    "    print(\"PCD Computation completed \\n\")\n",
    "    return lr_approx, rank_array, norm_array, time_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd0846-9b3f-41e8-b645-e0c69eecd494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#Pivoted_cholesky_gpu : to compute PCD in GPU \n",
    "\n",
    "#returns list : [approximated matrix LL^T, rank_list [1...max_rank], norm list containing norm LL^T for all ranks, time taken for each rank in GPU] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df035f-04ff-46ea-bc9f-bfde1f821305",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def pivoted_cholesky_gpu(matrix, max_rank,  max_error_tolerance=0.001):\n",
    "    \n",
    "    norm_array_gpu = []\n",
    "    rank_array_gpu = []\n",
    "    time_array_gpu = []\n",
    "\n",
    "    if max_rank > np.linalg.matrix_rank(matrix):\n",
    "            max_rank = np.linalg.matrix_rank(matrix)\n",
    "    \n",
    "    matrix_shape = np.asarray(matrix.shape)\n",
    "    matrix_diag = cp.diagonal(matrix)\n",
    "    orig_error = cp.amax(matrix_diag)\n",
    "    max_rank = cp.asnumpy(max_rank)\n",
    "    \n",
    "    start = timer()\n",
    "\n",
    "    def body(m, pchol, perm, matrix_diag):\n",
    "\n",
    "        maxi = np.argmax(matrix_diag[perm[m:]]) + m\n",
    "\n",
    "        maxval = matrix_diag[perm][maxi]\n",
    "        perm[m], perm[maxi] = perm[maxi], perm[m]\n",
    "\n",
    "        row = matrix[perm[m]][perm[m + 1:]]\n",
    "\n",
    "        # row = cp.array(row)\n",
    "        pchol = cp.asnumpy(pchol)\n",
    "\n",
    "        \n",
    "        def batch_gather(params, indices, axis=-1):\n",
    "            return cp.take(params, indices, axis=axis)\n",
    "        \n",
    "\n",
    "        prev_rows = pchol[..., :m, :]\n",
    "        prev_rows_perm_m_onward = batch_gather(prev_rows, perm[..., m + 1:])\n",
    "        prev_rows_pivot_col = batch_gather(prev_rows, perm[..., m:m + 1])\n",
    "        \n",
    "        row -= cp.sum(prev_rows_perm_m_onward * prev_rows_pivot_col, axis = -2)\n",
    "        pivot = np.sqrt(maxval)\n",
    "\n",
    "        row /= pivot\n",
    "        row = np.concatenate(([pivot], row), -1)\n",
    "        \n",
    "        matrix_diag_copy = matrix_diag.copy()\n",
    "        matrix_diag_copy[perm[m:]] -= row**2\n",
    "        \n",
    "        pchol[m, perm[m:]] = row\n",
    "        pchol_shape = pchol.shape\n",
    "\n",
    "        return m + 1, pchol, perm, matrix_diag_copy\n",
    "\n",
    "    m = cp.int64(0)\n",
    "    pchol = cp.zeros(matrix_shape, dtype=matrix.dtype)[..., :max_rank, :]\n",
    "    perm = np.broadcast_to(\n",
    "        range(matrix_shape[-1]), matrix_shape[:-1])\n",
    "    perm = perm.copy()\n",
    "\n",
    "    def check_cond(m, pchol, perm, matrix_diag):\n",
    "        del pchol\n",
    "        del perm\n",
    "        error = np.linalg.norm(matrix_diag, ord=1, axis=-1)\n",
    "        max_error = cp.amax(error / orig_error)\n",
    "        return (m >= max_rank) |( max_error <= max_error_tolerance)\n",
    "\n",
    "    while(1):\n",
    "        m, pchol, perm, matrix_diag = body(m, pchol, perm, matrix_diag)\n",
    "        pchol = cp.array(pchol)\n",
    "        pchol_T = cp.transpose(pchol)\n",
    "        lr_approx = cp.matmul(pchol_T, pchol)\n",
    "        time_array_gpu.append(timer() - start)  \n",
    "        rank_array_gpu.append(np.linalg.matrix_rank(lr_approx))\n",
    "        norm_array_gpu.append(np.linalg.norm(lr_approx))\n",
    "        if (m % 100 == 0):\n",
    "            print(\" computing... rank {} approximation completed (GPU) \\n\".format(m))\n",
    "        \n",
    "        if check_cond(m, pchol, perm, matrix_diag):\n",
    "            break\n",
    "            \n",
    "    print(\"PCD Computation completed \\n\")\n",
    "    return lr_approx, rank_array_gpu, norm_array_gpu, time_array_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc1a60-9f26-4b2e-b22d-9b3516b4944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivoted_cholesky. Returns only the low rank matrix 'L'. L*L_transpose would time the approximation\n",
    "#Use if no time or norm error analysis is needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366776f4-98c3-46e7-81a6-82446ec33243",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#[1]: H Harbrecht, M Peters, R Schneider. On the low-rank approximation by the pivoted Cholesky decomposition. Applied numerical mathematics, 62(4):428-440, 2012.\n",
    "#reference : https://github.com/tensorflow/probability/blob/v0.12.2/tensorflow_probability/python/math/linalg.py#L264-L404\n",
    "\n",
    "\n",
    "def pivoted_cholesky(matrix, max_rank,  max_error_tolerance=0.001):\n",
    "    \n",
    "    if max_rank > np.linalg.matrix_rank(matrix):\n",
    "            max_rank = np.linalg.matrix_rank(matrix)\n",
    "    \n",
    "    matrix_shape = np.asarray(matrix.shape)\n",
    "    matrix_diag = cp.diagonal(matrix)\n",
    "    orig_error = cp.amax(matrix_diag)\n",
    "    max_rank = cp.asnumpy(max_rank)\n",
    "    \n",
    "    start = timer()\n",
    "\n",
    "    def body(m, pchol, perm, matrix_diag):\n",
    "\n",
    "        maxi = np.argmax(matrix_diag[perm[m:]]) + m\n",
    "\n",
    "        maxval = matrix_diag[perm][maxi]\n",
    "        perm[m], perm[maxi] = perm[maxi], perm[m]\n",
    "\n",
    "        row = matrix[perm[m]][perm[m + 1:]]\n",
    "\n",
    "        # row = cp.array(row)\n",
    "        pchol = cp.asnumpy(pchol)\n",
    "\n",
    "        \n",
    "        def batch_gather(params, indices, axis=-1):\n",
    "            return cp.take(params, indices, axis=axis)\n",
    "        \n",
    "\n",
    "        prev_rows = pchol[..., :m, :]\n",
    "        prev_rows_perm_m_onward = batch_gather(prev_rows, perm[..., m + 1:])\n",
    "        prev_rows_pivot_col = batch_gather(prev_rows, perm[..., m:m + 1])\n",
    "        \n",
    "        row -= cp.sum(prev_rows_perm_m_onward * prev_rows_pivot_col, axis = -2)\n",
    "        pivot = np.sqrt(maxval)\n",
    "\n",
    "        row /= pivot\n",
    "        row = np.concatenate(([pivot], row), -1)\n",
    "        \n",
    "        matrix_diag_copy = matrix_diag.copy()\n",
    "        matrix_diag_copy[perm[m:]] -= row**2\n",
    "        \n",
    "        pchol[m, perm[m:]] = row\n",
    "        pchol_shape = pchol.shape\n",
    "\n",
    "        return m + 1, pchol, perm, matrix_diag_copy\n",
    "\n",
    "    m = cp.int64(0)\n",
    "    pchol = cp.zeros(matrix_shape, dtype=matrix.dtype)[..., :max_rank, :]\n",
    "    perm = np.broadcast_to(\n",
    "        range(matrix_shape[-1]), matrix_shape[:-1])\n",
    "    perm = perm.copy()\n",
    "\n",
    "    def check_cond(m, pchol, perm, matrix_diag):\n",
    "        del pchol\n",
    "        del perm\n",
    "        error = np.linalg.norm(matrix_diag, ord=1, axis=-1)\n",
    "        max_error = cp.amax(error / orig_error)\n",
    "        return (m >= max_rank) |( max_error <= max_error_tolerance)\n",
    "\n",
    "    while(1):\n",
    "        m, pchol, perm, matrix_diag = body(m, pchol, perm, matrix_diag)\n",
    "        pchol = cp.array(pchol)\n",
    "        if (m % 100 == 0):\n",
    "            print(\" computing... ...rank {} approximation completed (GPU) \\n\".format(m))\n",
    "        \n",
    "        if check_cond(m, pchol, perm, matrix_diag):\n",
    "            break\n",
    "    \n",
    "    print(\"PCD Computation completed \\n\")\n",
    "    pchol_T = cp.transpose(pchol)\n",
    "    return pchol_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b5635-1a4d-44c6-a5ec-9897415417e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kernel ridge regression implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02940b-43ce-46d5-b5fa-ea1c1865a942",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_krr(lr, ridge_parameter, X_train, y_train, X_test):\n",
    "\n",
    "    lr_approx_ridge = lr + cp.identity(len(X_train)) * ridge_parameter # adding ridge parameter\n",
    "    \n",
    "    alpha = cp.linalg.solve(lr_approx_ridge, y_train)  # solving for alpha \n",
    "\n",
    "    y_prediction = []\n",
    "    \n",
    "    X_train, X_test = cp.asnumpy(X_train), cp.asnumpy(X_test)\n",
    "    for j in range(len(X_test)):\n",
    "        x_test_val = X_test[j].reshape(1,-1)\n",
    "        pred = 0\n",
    "        for i in range(len(X_train)): #computing the predicted values and storing in the prediction vector\n",
    "            x_train_val = X_train[i].reshape(1,-1)\n",
    "            similarity = cp.array(sklearn.metrics.pairwise.laplacian_kernel(x_train_val, x_test_val)) # computing similarity between evaluation and training points \n",
    "            temp = alpha[i][0] * similarity[0]     \n",
    "            pred += temp[0]\n",
    "        y_prediction.append(pred)\n",
    "\n",
    "    return cp.asarray(y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d9bf95-2638-4660-a385-10739f89d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9041f7e-d397-4a8b-b99d-ff3a1cb83258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('energy.csv', usecols=['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8'])\n",
    "y = pd.read_csv('energy.csv', usecols=['Y1'])\n",
    "\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "# start_load = timer()\n",
    "\n",
    "# X = np.load('data/md17_X.npy')\n",
    "\n",
    "# y = np.load('data/md17_Y.npy')\n",
    "\n",
    "# print(\"load data time = \", timer() - start_load)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd756989-24e1-442b-b2eb-437b85ca7425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to use only 'n' rows of a large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ffd566-f116-47ec-8371-31b0b1165e4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_rows = 300 \n",
    "X = X[:number_of_rows]\n",
    "y = y[:number_of_rows]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72877bf4-d49b-4134-ad8c-0489510fb117",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test split, #create_kernel_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1eb47b-1e44-450a-9a12-b6ac10cdf09c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # train - test split - 4:1 (Use 20% for testing, rest for training) \n",
    "kernel_matrix = sklearn.metrics.pairwise.laplacian_kernel(X_train, Y=None, gamma=None) # Creating kernel matrix\n",
    "kernel_matrix.shape\n",
    "\n",
    "kernel_matrix.shape, np.linalg.norm(kernel_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7860b01b-2acc-433a-9006-00c1b4df57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test for pivoted_cholesky. returns L, compare norm of (LL^T) to norm of original kernel matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98170b58-53e0-48cc-b870-460622f79745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr_approx_gpu = pivoted_cholesky(kernel_matrix, 100, 0) \n",
    "len(lr_approx_gpu)\n",
    "\n",
    "print(\"norm of Kernel Matrix = \", cp.linalg.norm(kernel_matrix))\n",
    "\n",
    "norm_approx = cp.linalg.norm(cp.dot(lr_approx_gpu, lr_approx_gpu.T))\n",
    "                             \n",
    "print(\"Rank of L = {}, norm of approximated matrix LL^T = {}\".format(np.linalg.matrix_rank(lr_approx_gpu), norm_approx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1516f-0b67-4c65-8c5d-7613c93c0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute PCD on GPU\n",
    "#Get the result list: [LL^T, rank_list, norm_list, time_list]\n",
    "#function parameters: pivoted_cholesky_gpu(kernel_matrix, max_rank, error_tolerance=0(default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0831b77-80e5-4776-8ecb-cfdd0c7ac8e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = timer()\n",
    "pcd_gpu_results = pivoted_cholesky_gpu(kernel_matrix, 2400, 0) \n",
    "print(\"time taken in GPU= \", timer() - start )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890504b-4f08-400c-a42d-907c72ac9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute PCD on CPU\n",
    "#Get the result list: [LL^T, rank_list, norm_list, time_list]\n",
    "#function parameters: pivoted_cholesky_gpu(kernel_matrix, max_rank, error_tolerance=0(default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f07b86b-87ec-4231-a804-fe998e2c00a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "pcd_cpu_results = pivoted_cholesky_cpu(kernel_matrix, 2400, 0) \n",
    "print(\"time taken in CPU= \", timer() - start )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1a551-c4d3-45f5-b41b-a15197e1c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store cupy array values in separate list for easier plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378fbe3-18fd-4257-880a-91c104464fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lr_approx = pcd_gpu_results[0]\n",
    "\n",
    "\n",
    "rank_list = [cp.asnumpy(x) for x in pcd_gpu_results[1]]\n",
    "norm_list = [cp.asnumpy(x) for x in pcd_gpu_results[2]]\n",
    "time_list = pcd_gpu_results[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eb4658-33b4-481b-8b26-97fba7ab31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot results for rank vs error in norm. see specific results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb88898-ccb3-4b88-98ae-520b855a902e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title(\"Rank vs norm error\") \n",
    "plt.xlabel(\"Rank of approximated matrix\") \n",
    "plt.ylabel(\"Error in norm\") \n",
    "\n",
    "nr = 100 # gap between ranks in results shown\n",
    "\n",
    "orig_norm = np.linalg.norm(kernel_matrix)\n",
    "plt.plot(rank_list, orig_norm - norm_list)\n",
    "plt.show()\n",
    "# plt.savefig('./figures/768rank_norm.png')\n",
    "    \n",
    "print(\"rank {} error\".format(\"     \"))\n",
    "for n1, n2 in zip(rank_list, norm_list):\n",
    "    if (n1 < 10) or (n1 % nr == 0): \n",
    "        print(\"{}   &   {:.6f}\".format(n1, orig_norm - n2), \"   \\\\\\ \\hline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb1187-df45-474e-9af6-4dacf353b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot results for time taken for PCD CPU vs GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c75511-1969-402c-bf5f-9545f76bfec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.title(\"time taken as rank increases\") \n",
    "plt.xlabel(\"rank\") \n",
    "plt.ylabel(\"time(s)\") \n",
    "\n",
    "plt.plot(rank_list, pcd_cpu_results[3], 'r', time_list, 'g')\n",
    "plt.legend([\"time taken in cpu\", \"time taken in gpu\"], loc =\"lower right\")\n",
    "plt.savefig('./figures/time2.png')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# lr_approx[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57050309-7fa5-49b4-a2f7-e0eaf159f6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot speed up in gpu increasing rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff706464-8810-4989-9b83-0e201a7d8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_up = []\n",
    "for i, j in zip(pcd_cpu_results[3], time_list):\n",
    "    speed_up.append(i/j)\n",
    "    \n",
    "plt.title(\"GPU speed up as matrix size increases\") \n",
    "plt.xlabel(\"rank\") \n",
    "plt.ylabel(\"speedup\") \n",
    "\n",
    "plt.plot(rank_list, speed_up, 'g')\n",
    "plt.savefig('./figures/speedup_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28941fa8-2c81-40b0-8d02-f4227627568f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.linalg.norm(pcd_gpu_results[0]), np.linalg.norm(kernel_matrix), np.linalg.matrix_rank(pcd_gpu_results[0]), np.linalg.matrix_rank(kernel_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0620883-b86a-4d39-a714-62824d319180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel ridge regression Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eba9fc-acc0-4e27-baee-ebdafccd518c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def execute_krr(lr, ridge_parameter, X_train, y_train, X_test):\n",
    "\n",
    "    lr_approx_ridge = lr + cp.identity(len(X_train)) * ridge_parameter # adding ridge parameter\n",
    "    \n",
    "    alpha = cp.linalg.solve(lr_approx_ridge, y_train)  # solving for alpha \n",
    "\n",
    "    y_prediction = []\n",
    "    \n",
    "    X_train, X_test = cp.asnumpy(X_train), cp.asnumpy(X_test)\n",
    "    for j in range(len(X_test)):\n",
    "        x_test_val = X_test[j].reshape(1,-1)\n",
    "        pred = 0\n",
    "        for i in range(len(X_train)): #computing the predicted values and storing in the prediction vector\n",
    "            x_train_val = X_train[i].reshape(1,-1)\n",
    "            similarity = cp.array(sklearn.metrics.pairwise.laplacian_kernel(x_train_val, x_test_val)) # computing similarity between evaluation and training points \n",
    "            temp = alpha[i][0] * similarity[0]     \n",
    "            pred += temp[0]\n",
    "        y_prediction.append(pred)\n",
    "\n",
    "    return cp.asarray(y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1866a201-968a-4543-b6e8-28c6c7e03c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop to execute krr for Different rank approximations of the kernel matrix and generate results(RMSE as the generalization error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41964129-fae1-4cb9-b91d-3bea0ed37135",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_rank_values = [100, 200, 250, 300] # values for ranks to experiment on\n",
    "X_train_cp, y_train_cp, X_test_cp, y_test_cp, kernel_matrix_cp = cp.array(X_train), cp.array(y_train), cp.array(X_test), cp.array(y_test), cp.array(kernel_matrix)\n",
    "\n",
    "rank_err = []\n",
    "\n",
    "rank_pred = []\n",
    "\n",
    "ridge_parameter = 0.001\n",
    "\n",
    "for rank_value in max_rank_values:\n",
    "    lr_approx_gpu = pivoted_cholesky_gpu(kernel_matrix, rank_value, 0) \n",
    "    y_predarray_gpu = execute_krr(lr_approx_gpu[0], ridge_parameter, X_train_cp, y_train_cp, X_test_cp)  \n",
    "    \n",
    "    rmse_krr_manual_gpu = np.sqrt(mean_squared_error(y_test, cp.asnumpy(y_predarray_gpu))) #compute root mean squared error for generalization error of that rank\n",
    "    \n",
    "    print(\"RMSE(root mean squared error) for {} rank approximation = {}\".format(rank_value, rmse_krr_manual_gpu, \"\\n\"))\n",
    "    \n",
    "    print(\"____________________________________________________________________________-\")\n",
    "    \n",
    "    \n",
    "    rank_pred.append(rmse_krr_manual_gpu) # add rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5902158-ba0b-4737-b687-a7b50fb54666",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"plot\" generalization error vs rank with the constant values in max_rank_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c09707-9c09-414f-82b6-42a21b3957e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Generalization error per rank\") \n",
    "plt.xlabel(\"Rank\") \n",
    "plt.ylabel(\"generalization error: rmse\") \n",
    "\n",
    "plt.plot(max_rank_values, rank_pred)\n",
    "plt.legend([\"ridge parameter = {}\".format(ridge_parameter)])\n",
    "plt.savefig('./figures/rmse.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
